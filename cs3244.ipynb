{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4acb7a-64dd-4107-9ee4-d0ee582724f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dff234-7a99-4b49-88af-0a40d98ef085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "\n",
    "file = glob.glob('./clothing-dataset-small-master.zip')\n",
    "\n",
    "with zipfile.ZipFile(file[0], 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98320d99-d645-4720-97f3-7980eac9159f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './data/clothing-dataset-processed/train\\\\shorts\\\\3f7d16eb-7c7b-45fe-8d3b-ffb38124b52c.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m new_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(new_folder_path, folder, filename)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_image_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# flip all images besides t-shirts to balance the data\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m folder \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt-shirt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:2428\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2426\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2427\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2428\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2431\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './data/clothing-dataset-processed/train\\\\shorts\\\\3f7d16eb-7c7b-45fe-8d3b-ffb38124b52c.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# combine train and validation datasets + resize and grayscale images\n",
    "for data_type in [\"train\", \"test\", \"validation\"]:\n",
    "    folder_path = \"./data/clothing-dataset-small-master/\" + data_type\n",
    "    \n",
    "    new_data_type = data_type if data_type == \"test\" else \"train\"\n",
    "    new_folder_path = \"./data/clothing-dataset-processed/\" + new_data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        new_path = os.path.join(new_folder_path, folder)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                img = Image.open(image_path)\n",
    "                img = img.resize((64, 64))\n",
    "                img = img.convert('L')\n",
    "                new_image_path = os.path.join(new_folder_path, folder, filename)\n",
    "                img.save(new_image_path)\n",
    "                \n",
    "                # flip all images besides t-shirts to balance the data\n",
    "                if data_type != \"test\" and folder != \"t-shirt\":\n",
    "                    flipped_filename = \"flipped_\" + filename\n",
    "                    flipped_image_path = os.path.join(new_folder_path, folder, flipped_filename)\n",
    "                    flippedImg = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                    flippedImg.save(flipped_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e4ebdb3-1e65-431a-9801-8c36916a43c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "train_folder = \"./data/clothing-dataset-processed/train\"\n",
    "for folder in os.listdir(train_folder):\n",
    "    for filename in os.listdir(os.path.join(train_folder, folder)):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(train_folder, folder, filename)\n",
    "            img = Image.open(image_path)\n",
    "            array = np.array(img).ravel()\n",
    "            X_train.append(array)\n",
    "            y_train.append(folder)\n",
    "            \n",
    "X_test = []\n",
    "y_test = []\n",
    "test_folder = \"./data/clothing-dataset-processed/test\"\n",
    "for folder in os.listdir(test_folder):\n",
    "    for filename in os.listdir(os.path.join(test_folder, folder)):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(test_folder, folder, filename)\n",
    "            img = Image.open(image_path)\n",
    "            array = np.array(img).ravel()\n",
    "            X_test.append(array)\n",
    "            y_test.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667cc79-34c5-401d-a690-4f28ce4f5eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 49\n",
      "Best accuracy: 0.3602150537634409\n",
      "Validation accuracy: 0.41642228739002934\n"
     ]
    }
   ],
   "source": [
    "# KNN using grayscale pixel values\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "max_accuracy = 0\n",
    "k = 2\n",
    "for i in range(2, 100):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        k = i\n",
    "\n",
    "print(\"Best k: \" + str(k))\n",
    "print(\"Best accuracy: \" + str(max_accuracy))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_val)\n",
    "print(\"Validation accuracy: \" + str(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d645f-cece-4412-a3b2-eca1552809cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 45\n",
      "Best accuracy: 0.3387096774193548\n",
      "Validation accuracy: 0.34310850439882695\n"
     ]
    }
   ],
   "source": [
    "# DT using grayscale pixel values\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "max_accuracy = 0\n",
    "max_depth = 2\n",
    "for i in range(2, 100):\n",
    "    dt = DecisionTreeClassifier(max_depth=i, max_features=2048)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        max_depth = i\n",
    "\n",
    "print(\"Best depth: \" + str(max_depth))\n",
    "print(\"Best accuracy: \" + str(max_accuracy))\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=max_depth, max_features=2048)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_val)\n",
    "print(\"Validation accuracy: \" + str(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd1fb93-9d11-40a8-823f-cc4556c427c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread, imshow\n",
    "from skimage import transform\n",
    "from skimage.filters import prewitt\n",
    "import os\n",
    "\n",
    "def preprocess_image_edge_only(image):\n",
    "    resized_image = transform.resize(image, (256, 256), anti_aliasing=True)\n",
    "    edges_prewitt = prewitt(resized_image)\n",
    "    edges_prewitt_array = edges_prewitt.reshape(1, 256 * 256)[0]\n",
    "    return edges_prewitt_array\n",
    "\n",
    "def preprocess_image(image):\n",
    "    resized_image = transform.resize(image, (256, 256), anti_aliasing=True)\n",
    "    edges_prewitt = prewitt(resized_image)\n",
    "    edges_prewitt_array = edges_prewitt.reshape(1, 256 * 256)\n",
    "    image_array = resized_image.reshape(1, 256 * 256)\n",
    "    return np.concatenate((edges_prewitt_array[0], image_array[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a22c5e0-d7bd-44b6-8275-fbc68bafb929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "data_types = [\"train\", \"test\", \"validation\"]\n",
    "\n",
    "image = None\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset-small-master/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                image = imread(image_path,as_gray=True)\n",
    "                result = preprocess_image_edge_only(image)\n",
    "                if data_type == \"train\":\n",
    "                    X_train.append(result)\n",
    "                    y_train.append(folder)\n",
    "                elif data_type == \"test\":\n",
    "                    X_test.append(result)\n",
    "                    y_test.append(folder)\n",
    "                elif data_type == \"validation\":\n",
    "                    X_val.append(result)\n",
    "                    y_val.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749dc2e1-ba0f-4211-bee2-5b0c62bc396d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 79\n",
      "Best accuracy: 0.19086021505376344\n",
      "Validation accuracy: 0.2961876832844575\n"
     ]
    }
   ],
   "source": [
    "# KNN using edge operators to extract shape\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "max_accuracy = 0\n",
    "k = 2\n",
    "for i in range(2, 100):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        k = i\n",
    "\n",
    "print(\"Best k: \" + str(k))\n",
    "print(\"Best accuracy: \" + str(max_accuracy))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_val)\n",
    "print(\"Validation accuracy: \" + str(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1bc8adf-22e7-4d00-b248-37bed1402957",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best maximum depth: 70\n",
      "Best accuracy: 0.22311827956989247\n",
      "Validation accuracy: 0.22287390029325513\n"
     ]
    }
   ],
   "source": [
    "# DT using edge operators to extract shape\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_accuracy = 0\n",
    "depth = 5\n",
    "for i in range(2, 100):\n",
    "    dt = DecisionTreeClassifier(max_depth=i, max_features=2048)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        depth = i\n",
    "\n",
    "print(\"Best maximum depth: \" + str(depth))\n",
    "print(\"Best accuracy: \" + str(max_accuracy))\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=depth, max_features=2048)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_val)\n",
    "print(\"Validation accuracy: \" + str(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df749708-8851-430d-8acc-94382341a1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "data_types = [\"train\", \"test\", \"validation\"]\n",
    "\n",
    "image = None\n",
    "count = 0\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset-small-master/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                image = imread(image_path,as_gray=True)\n",
    "                result = preprocess_image(image)\n",
    "                if data_type == \"train\":\n",
    "                    X_train.append(result)\n",
    "                    y_train.append(folder)\n",
    "                elif data_type == \"test\":\n",
    "                    X_test.append(result)\n",
    "                    y_test.append(folder)\n",
    "                elif data_type == \"validation\":\n",
    "                    X_val.append(result)\n",
    "                    y_val.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b86bcd-033f-4359-9a45-5ed58e547cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 64\n",
      "Best accuracy: 0.3602150537634409\n",
      "Validation accuracy: 0.40762463343108507\n"
     ]
    }
   ],
   "source": [
    "# KNN using both edge operators and grayscale pixel values\n",
    "\n",
    "max_accuracy = 0\n",
    "k = 2\n",
    "for i in range(2, 100):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        k = i\n",
    "\n",
    "print(\"Best k: \" + str(k))\n",
    "print(\"Best accuracy: \" + str(max_accuracy))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_val)\n",
    "print(\"Validation accuracy: \" + str(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014dd90-5dc1-4689-9d0c-83f3070c702f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best maximum depth: 15\n",
      "Best accuracy: 0.3575268817204301\n",
      "Validation accuracy: 0.2903225806451613\n"
     ]
    }
   ],
   "source": [
    "# DT using both edge operators and grayscale pixel values\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_accuracy = 0\n",
    "depth = 5\n",
    "for i in range(2, 100):\n",
    "    dt = DecisionTreeClassifier(max_depth=i, max_features=2048)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        depth = i\n",
    "\n",
    "print(\"Best maximum depth: \" + str(depth))\n",
    "print(\"Best accuracy: \" + str(max_accuracy))\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=depth, max_features=2048)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_val)\n",
    "print(\"Validation accuracy: \" + str(accuracy_score(y_val, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
