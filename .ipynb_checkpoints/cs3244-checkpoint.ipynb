{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4acb7a-64dd-4107-9ee4-d0ee582724f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6dff234-7a99-4b49-88af-0a40d98ef085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "\n",
    "file = glob.glob('./clothing-dataset-small-master.zip')\n",
    "\n",
    "with zipfile.ZipFile(file[0], 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0f5491-21de-454f-ab7e-d7dcc901a7df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data_type in [\"train\", \"validation\", \"test\"]:\n",
    "    folder_path = \"./data/clothing-dataset-small-master/\" + data_type\n",
    "    \n",
    "    # combine validation and train\n",
    "    new_folder_path = \"./data/clothing-dataset/\" + (\"test\" if data_type == \"test\" else \"train\")\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        new_path = os.path.join(new_folder_path, folder)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                img = Image.open(image_path)\n",
    "                new_image_path = os.path.join(new_folder_path, folder, filename)\n",
    "                img.save(new_image_path)\n",
    "                                              \n",
    "                # flip all images besides t-shirts to balance the data\n",
    "                if folder != \"t-shirt\":\n",
    "                    img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                    new_image_path = os.path.join(new_folder_path, folder, \"flipped_\" + filename)\n",
    "                    img.save(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98320d99-d645-4720-97f3-7980eac9159f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature: Grayscale\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for data_type in [\"train\", \"test\"]:\n",
    "    folder_path = \"./data/clothing-dataset/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                img = Image.open(image_path)\n",
    "                # resize the image\n",
    "                img = img.resize((64, 64))\n",
    "                # convert to grayscale\n",
    "                img = img.convert('L')\n",
    "                # flatten to 1D array\n",
    "                array = np.array(img).ravel()\n",
    "                \n",
    "                if data_type == \"test\":\n",
    "                    X_test.append(array)\n",
    "                    y_test.append(folder)\n",
    "                else:\n",
    "                    X_train.append(array)\n",
    "                    y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd1fb93-9d11-40a8-823f-cc4556c427c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread, imshow\n",
    "from skimage import transform\n",
    "from skimage.filters import prewitt\n",
    "\n",
    "def preprocess_image_edge_only(image):\n",
    "    resized_image = transform.resize(image, (64, 64), anti_aliasing=True)\n",
    "    edges_prewitt = prewitt(resized_image)\n",
    "    edges_prewitt_array = edges_prewitt.reshape(1, 64 * 64)\n",
    "    return edges_prewitt_array[0]\n",
    "\n",
    "def preprocess_image(image):\n",
    "    resized_image = transform.resize(image, (64, 64), anti_aliasing=True)\n",
    "    edges_prewitt = prewitt(resized_image)\n",
    "    edges_prewitt_array = edges_prewitt.reshape(1, 64 * 64)\n",
    "    image_array = resized_image.reshape(1, 64 * 64)\n",
    "    return np.concatenate((edges_prewitt_array[0], image_array[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a22c5e0-d7bd-44b6-8275-fbc68bafb929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature: Edges\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "image = None\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                image = imread(image_path,as_gray=True)\n",
    "                result = preprocess_image_edge_only(image)\n",
    "                if data_type == \"test\":\n",
    "                    X_test.append(result)\n",
    "                    y_test.append(folder)\n",
    "                else:\n",
    "                    X_train.append(result)\n",
    "                    y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df749708-8851-430d-8acc-94382341a1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature: Grayscale + Edges\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "image = None\n",
    "count = 0\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                image = imread(image_path,as_gray=True)\n",
    "                result = preprocess_image(image)\n",
    "                if data_type == \"test\":\n",
    "                    X_test.append(result)\n",
    "                    y_test.append(folder)\n",
    "                else:\n",
    "                    X_train.append(result)\n",
    "                    y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0446c4-811f-4794-bb3d-4847852e8a00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "Best k:  {'n_neighbors': 13}\n",
      "Best F1 score:  0.48636646815788953\n",
      "Test F1 Score:  0.32947976878612717\n",
      "DT:\n",
      "Best depth:  {'max_depth': 65}\n",
      "Best F1 score:  0.3658659768415866\n",
      "Test F1 Score:  0.29335260115606937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# define the number of folds for cross validation\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "# define param search space for knn and dt\n",
    "knn_param_grid = {'n_neighbors': list(range(2, 100))}\n",
    "dt_param_grid = {'max_depth': list(range(2, 100))}\n",
    "\n",
    "# define models\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier(max_features=512)\n",
    "\n",
    "# define scoring metric\n",
    "f1_scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "# KNN\n",
    "knn_model = RandomizedSearchCV(knn, knn_param_grid, cv=NUM_FOLDS, scoring=f1_scorer, n_jobs=-1)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"KNN:\")\n",
    "print(\"Best k: \", knn_model.best_params_)\n",
    "print(\"Best F1 score: \", knn_model.best_score_)\n",
    "\n",
    "knn_final = KNeighborsClassifier(n_neighbors=int(knn_model.best_params_['n_neighbors']))\n",
    "knn_final.fit(X_train, y_train)\n",
    "y_pred = knn_final.predict(X_test)\n",
    "print(\"Test F1 Score: \", f1_score(y_test, y_pred, average='micro'))\n",
    "\n",
    "# DT\n",
    "dt_model = RandomizedSearchCV(dt, dt_param_grid, cv=NUM_FOLDS, scoring=f1_scorer, n_jobs=-1)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"DT:\")\n",
    "print(\"Best depth: \", dt_model.best_params_)\n",
    "print(\"Best F1 score: \", dt_model.best_score_)\n",
    "\n",
    "dt_final = DecisionTreeClassifier(max_depth=int(dt_model.best_params_['max_depth']), max_features=512)\n",
    "dt_final.fit(X_train, y_train)\n",
    "y_pred = dt_final.predict(X_test)\n",
    "print(\"Test F1 Score: \", f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e0dc30f-255e-4cc7-b19d-df305fc3f58c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score:  0.30346820809248554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tayya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# SVM\n",
    "svc = make_pipeline(StandardScaler(), SGDClassifier(max_iter=3000))\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(\"Test F1 Score: \", f1_score(y_test, y_pred, average='micro'))\n",
    "\n",
    "# svm_model = RandomizedSearchCV(svc, param_distributions=param_dist, cv=2, scoring=f1_scorer, n_jobs=-1, n_iter=2)\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "# print(\"SVM\")\n",
    "# print(\"Best params: \", svm_model.best_params_)\n",
    "# print(\"Best F1 score: \", svm_model.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
